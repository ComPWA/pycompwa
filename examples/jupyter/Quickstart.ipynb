{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this example, it is shown how to use ComPWA via the Python interface. We use the decay  $J/\\Psi \\rightarrow \\gamma \\pi^0 \\pi^0$ to illustrate the usual workflow is:\n",
    "\n",
    "1. Create an amplitude model for the decay.\n",
    "2. Generate a Monte Carlo data sample (hit & miss) using this model. \n",
    "3. Perform a fit on the data sample using the Minuit2 interface.\n",
    "4. Visualize the data and the fit result\n",
    "5. Calculating fit fractions\n",
    "\n",
    "In each step, we store the output, so that you can pick up your work at a later stage (like after performing a fit that takes several hours).\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we `import` the necessary components of the expert system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycompwa.expertsystem.ui.system_control import (\n",
    "    StateTransitionManager, InteractionTypes)\n",
    "from pycompwa.expertsystem.amplitude.helicitydecay import (\n",
    "    HelicityAmplitudeGeneratorXML)\n",
    "\n",
    "# just a little function to print the intermediate states\n",
    "def print_intermediate_states(solutions):\n",
    "    from pycompwa.expertsystem.topology.graph import (\n",
    "        get_intermediate_state_edges)\n",
    "    print(\"intermediate states:\")\n",
    "    intermediate_states = set()\n",
    "    for g in solutions:\n",
    "        edge_id = get_intermediate_state_edges(g)[0]\n",
    "        intermediate_states.add(g.edge_props[edge_id]['@Name'])\n",
    "    print(intermediate_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating the amplitude model\n",
    "\n",
    "### 1.1. Define problem set for this decay\n",
    "\n",
    "We first define the boundary conditions of our physics problem, such as initial state, final state, formalism type, etc. and pass all of that information to the `StateTransitionManager`. This is the main user interface class of the ComPWA expert system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [(\"J/psi\", [-1, 1])]\n",
    "final_state = [(\"gamma\", [-1, 1]), (\"pi0\", [0]), (\"pi0\", [0])]\n",
    "\n",
    "tbd_manager = StateTransitionManager(initial_state, final_state,\n",
    "                                     formalism_type='helicity',\n",
    "                                     topology_building='isobar')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   The ``StateTransitionManager`` (STM) is the main user interface class of the\n",
    "   ComPWA expert system. The boundary conditions of your physics problem are \n",
    "   defined here, such as the initial state, final state, formalism type, ...\n",
    "\n",
    "   * ``prepare_graphs()`` of the STM creates all topology graphs, here using\n",
    "     the isobar model (a tree of two-body decays). It also initializes the\n",
    "     graphs with the initial and final state and a set of conservation laws at\n",
    "     each interaction node.\n",
    "\n",
    "   * By default, all three interaction types (strong, EM, weak) are used in the\n",
    "     preparation stage. However, it is also possible to choose the allowed\n",
    "     interaction types globally via ``set_allowed_interaction_types()``.\n",
    "\n",
    "   After the preparation step, you can modify the settings returned by\n",
    "   ``prepare_graphs()`` to your liking. Since this output contains quite a lot\n",
    "   of information, the `expertsystem UI <pycompwa.expertsystem.ui>` aids in the\n",
    "   configuration (especially the STM).\n",
    "   \n",
    "   * A subset of particles that are allow as intermediate states can also be\n",
    "     specified in the STM. Either in the ``init()`` of the STM or setting the\n",
    "     instance attribute ``allowed_intermediate_particles``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Preparation\n",
    "Create all topology graphs using the **isobar model** (tree of two-body decays) and initialize the graphs with the initial and final state. Remember that each interaction node defines its own set of conservation laws.\n",
    "\n",
    "The `StateTransitionManager` (STM) defines three interaction types:\n",
    "\n",
    "| Interaction          | Strength  |\n",
    "| -------------------- | --------- |\n",
    "| strong               | $60$      |\n",
    "| electromagnetic (EM) | $1$       |\n",
    "| weak                 | $10^{-4}$ |\n",
    "\n",
    "By default, all three are used in the preparation stage. The function `prepare_graphs()` of the STM generates graphs with all possible combinations of interaction nodes. An overall interaction strength is assigned to each graph and they are grouped according to this strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Finding solutions\n",
    "If you are happy with the default settings generated by the ``StateTransitionManager``, just start with solving directly!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   This step takes about 30 sec on a Intel(R) Core(TM) i7-6820HQ CPU @ 2.70GHz running multi-threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a lot of solutions that are actually heavily suppressed (they involve two weak decays).\n",
    "\n",
    "In general, you can modify the dictionary returned by `prepare_graphs()` directly, but the STM also comes with functionality to globally choose the allowed interaction types (`set_allowed_interaction_types()`).\n",
    "\n",
    "So, go ahead and **disable** the **EM** and **weak** interaction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd_manager.set_allowed_interaction_types(\n",
    "    [InteractionTypes.Strong])\n",
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, what happened here? Actually, since a **$\\gamma$ particle** appears in one of the interaction nodes, the expert system knows that this node **must involve EM interactions**! Because the node can be an effective interaction, the weak interaction cannot be excluded, as it contains only a subset of conservation laws.\n",
    "\n",
    "Since only the strong interaction was supposed to be used, this results in a warning and the STM automatically corrects the mistake.\n",
    "\n",
    "Once the EM interaction is included, this warning disappears. Be aware, however, that the EM interaction is now available globally. Hence, there now might be solutions in which both nodes are electromagnetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd_manager.set_allowed_interaction_types(\n",
    "    [InteractionTypes.Strong, InteractionTypes.EM])\n",
    "graph_interaction_settings_groups = tbd_manager.prepare_graphs()\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we selected only the strongest contributions. Be aware, though, that there are more effects that can suppress certain decays. For example branching ratios. In this example $J/\\Psi$ can decay into $\\pi^0 + \\rho^0$ or $\\pi^0 + \\omega$.\n",
    "\n",
    "| decay                               | branching ratio |\n",
    "| ----------------------------------- | --------------- |\n",
    "| $$\\omega \\rightarrow \\gamma+\\pi^0$$ | 0.0828          |\n",
    "| $$\\rho^0 \\rightarrow \\gamma+\\pi^0$$ | 0.0006          |\n",
    "\n",
    "Unfortunately, the $\\rho^0$ mainly decays into $\\pi+\\pi$, not $\\gamma+\\pi^0$ and is therefore suppressed. This information is currently not known to the expert system, but it is possible to hand the expert system a list of allowed intermediate states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particles are found by name comparison, i.e. f2 will find all f2's and f all f's independent of their spin\n",
    "tbd_manager.allowed_intermediate_particles = ['f']\n",
    "\n",
    "(solutions, violated_rules) = tbd_manager.find_solutions(\n",
    "        graph_interaction_settings_groups)\n",
    "\n",
    "print(\"found \" + str(len(solutions)) + \" solutions!\")\n",
    "print_intermediate_states(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have selected all amplitudes that involve **f** states. The appearing warnings notify the user that the solution space is only partial. For certain lines in the graph, no suitable particle was found (since only f states were allowed).\n",
    "\n",
    "At this point, we are all set to generate some data using this amplitude model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_generator = HelicityAmplitudeGeneratorXML()\n",
    "xml_generator.generate(solutions)\n",
    "xml_generator.write_to_file('model.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look through the sections of the resulting ``model.xml`` file to see what you recognize from the problem set defined so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate a data sample\n",
    "\n",
    "In this section, we will use the amplitude model created above to generate a data sample via hit & miss Monte Carlo.\n",
    "\n",
    "Using this amplitude model in the C++ side of ComPWA is simple. The `create_helicity_kinematics()` helper function builds a ``Kinematics`` object following the specifications in the XML model file. The second argument of this function is a particle list, which can be created with the `read_particles()` function. The created ``Kinematics`` object can be used to generate a phase space sample as well.\n",
    "\n",
    "An ``Intensity`` object can be created with the `create_intensity()` function. Because the Intensities constructed by the Builder are automatically normalized, you have to pass this function a phase space sample as an argument. The ``Kinematics`` instance is then updated with the needed subsystems of the decay topology during the creation of the ``Intensity`` object.\n",
    "\n",
    "Now all building blocks for generating our data sample are at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycompwa.ui as pwa\n",
    "\n",
    "particle_list = pwa.read_particles('model.xml')\n",
    "\n",
    "kinematics = pwa.create_helicity_kinematics('model.xml', particle_list)\n",
    "\n",
    "generator = pwa.EvtGenGenerator(kinematics.get_particle_state_transition_kinematics_info())\n",
    "\n",
    "random_generator = pwa.StdUniformRealGenerator(12345)\n",
    "\n",
    "phsp_sample = pwa.generate_phsp(100000, generator, random_generator)\n",
    "\n",
    "intensity_builder = pwa.IntensityBuilderXML('model.xml', particle_list, kinematics, phsp_sample)\n",
    "\n",
    "intensity = intensity_builder.create_intensity()\n",
    "\n",
    "data_sample = pwa.generate(10000, kinematics, generator, intensity, random_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Writing and reading data samples\n",
    "\n",
    "You may want to write the generated data and phase space samples to disk, so that you don't have to perform this step each time you revisit the fit. ComPWA provides functions for ROOT and ASCII files, that can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ROOT\n",
    "pwa.write_root_data(event_list=data_sample, output_file='generated_data.root')\n",
    "pwa.write_root_data(event_list=phsp_sample, output_file='generated_phsp.root')\n",
    "# to ASCII\n",
    "pwa.write_ascii_data(event_list=data_sample, output_file='generated_data.dat')\n",
    "pwa.write_ascii_data(event_list=phsp_sample, output_file='generated_phsp.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing syntax parallels that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_data = pwa.read_root_data(input_file='generated_data.root')\n",
    "print('Imported events:', len(imported_data.events))\n",
    "first_event = imported_data.events[0]\n",
    "print('First event:')\n",
    "print(first_event.four_momenta)\n",
    "print(first_event.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ASCII (`.dat`) files contain a header section that informs you about the final state of the file. You will have to prepend this section to the file yourself if you want to use a data sample from another framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated_data.dat') as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline()[:-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   ``pycompwa.ui`` is the python interface to ComPWA's C++ modules. Read more\n",
    "   about this :ref:`here <python-ui>`.\n",
    "\n",
    "   Three important pieces for evaluating an intensity are:\n",
    "\n",
    "   * The **Intensity** object itself. It was generated previously and stored\n",
    "     within the XML model file.\n",
    "  \n",
    "   * A **DataSample** (``EventCollection``). In its raw form a data sample is just an\n",
    "     event-based list of four-momenta with a list of Particle IDs. For the evaluation\n",
    "     of the intensity, the kinematic variables are required as well. Here, the\n",
    "     kinematics class comes into play!\n",
    "   \n",
    "   * A **Kinematics** instance. It handles the calculation of the kinematic\n",
    "     variables that are required for the evaluation of the intensity!\n",
    "     For example in the helicity formalism: :math:`(s,\\theta,\\phi)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fitting\n",
    "\n",
    "An **Intensity** object behaves just like a mathematical function that takes a `DataSet` as an argument and returns a list of intensities (real numbers).\n",
    "\n",
    "To perform a fit, first create an estimator of your choice. An estimator generally needs:\n",
    "\n",
    "- an `Intensity` instance\n",
    "- a `DataSet` (to which the intensity is fitted)\n",
    "- optionally: a phase space `DataSet` (which is used to normalize the `Intensity`)\n",
    "\n",
    "A phase space sample can be generated via the `generate_phsp()` function (see above). Since our `Intensity` is already normalized, this is not needed here.\n",
    "The data samples can be converted to `DataSet` using the `convert()` method of `Kinematics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = kinematics.convert(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an **estimator**. Remember that an estimator indicates how well a set of model parameters describes a given data set best. In this example, we use an unbinned log likelihood estimator. The fit calculations are then performed the calculations with the `FunctionTree` back-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, initial_parameters = pwa.create_unbinned_log_likelihood_function_tree_estimator(intensity, \n",
    "                                                                                           data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you not only receive a estimator object, but also a list of fit parameters (`FitParameterList`). You use this list of fit parameters to initialize the optimizer later on. They contain the following info:\n",
    "\n",
    "- the initial values of the parameters\n",
    "- fix parameters\n",
    "- define boundaries\n",
    "- define errors, which can give certain optimizers hints on the step size\n",
    "\n",
    "These fit parameters are initialized with the values stated in the XML file or with default values if unspecified. But can be changed easily in Python as well, like fixing certain parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(initial_parameters)\n",
    "print(\"\\nthis parameter is initially not fixed:\")\n",
    "print(initial_parameters[8])\n",
    "initial_parameters[7].is_fixed = True\n",
    "initial_parameters[8].is_fixed = True\n",
    "print(\"\\nand now it is fixed:\")\n",
    "print(initial_parameters[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the fit a bit more interesting, we modify one of the parameters to a different initial value than the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before:\")\n",
    "print(initial_parameters[12])\n",
    "initial_parameters[12].value = 2.0\n",
    "print(\"after:\")\n",
    "print(initial_parameters[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start up a set up a fit. This is quite simple: just create an optimizer instance of your choice, here Minuit2 (`MinuitIF`), and call its `optimize()` method to start the fitting process."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "   The fit (with 14 free parameters) on a Intel(R) Core(TM) i7-6820HQ CPU @ 2.70GHz takes about 15 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pwa.MinuitIF()\n",
    "fit_result = optimizer.optimize(estimator, initial_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result.fit_duration_in_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the fit parameters are \"close to\" the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"this should be close to 1.0 again:\")\n",
    "print(fit_result.final_parameters[12].value, \n",
    "      \"+-\", \n",
    "      fit_result.final_parameters[12].error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Note that the intensity instance still needs to be notified about this optimal set of parameters. They can be applied with the `updateParametersFrom()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity.updateParametersFrom(fit_result.final_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can store this fit result to disk and pick it up again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result.write('fit_result.xml')\n",
    "imported_fit_result = pwa.load('fit_result.xml')\n",
    "imported_fit_result.final_parameters[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualization\n",
    "\n",
    "Let's go ahead and make a Dalitz plot of the data sample and our fit result. It is easiest to visualize your data with [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). This section illustrates how to do this in combination with ComPWA's functionality.\n",
    "\n",
    "Since our model only includes one specific decay topology, the `HelicityKinematics` class only generates the kinematic variables needed to evaluate the `Intensity`. In order to make a Dalitz plot, the kinematic variables from the other subsystems are also needed. They can be created with `create_all_subsystems()`. The conversion from the event samples have to be performed again, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics.create_all_subsystems()\n",
    "data_set = kinematics.convert(data_sample)\n",
    "phsp_set = kinematics.convert(phsp_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data_set` and `phsp_set` instances are `DataSet` objects can cannot be understood by pandas. Their data members, however, easily allow us to make the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frame_data = pd.DataFrame(data_set.data)\n",
    "frame_phsp = pd.DataFrame(phsp_set.data)\n",
    "frame_data['weights'] = data_set.weights\n",
    "frame_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a weights column here as well, though in this case, all data weights are unity.\n",
    "\n",
    "To change the number IDs here to the original particle names, you can extract a mapping from the `Kinematics` object:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. tip::\n",
    "   \n",
    "   ComPWA ships with a little python plotting module (``plotting``), which for example helps you to read in ROOT TTree's and create common plots (e.g. angular distributions, Dalitz plots). It uses matplotlib as a backend. You can either hand it data files, or feed it directly with data.\n",
    "\n",
    "   Please use it, instead of creating your own visualization scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_info = kinematics.get_particle_state_transition_kinematics_info()\n",
    "id_to_name = transition_info.get_final_state_id_to_name_mapping()\n",
    "name_to_id = {val: key for key, val in id_to_name.items()}\n",
    "def replace_ids(title):\n",
    "    \"\"\"Just some replace lambda\"\"\"\n",
    "    for id, name in id_to_name.items():\n",
    "       title = title.replace(str(id), name)\n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to visualize the fit? This is where the phase space comes in again. By attributing an intensity as a weight to each phase space point, we get a point distribution of the fit model over the space spanned by the kinematic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_set = intensity.evaluate(phsp_set.data)\n",
    "frame_phsp['weights'] = intensity_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can apply the usual `matplotlib.pyplot` tools to plot the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_1d_comparison(name, **kwargs):\n",
    "    \"\"\"Helper function for comparing the 1D distributions of fit and data\"\"\"\n",
    "    frame_data[name].hist(bins=100, density=True, alpha=.5, label='data', **kwargs);\n",
    "    frame_phsp[name].hist(bins=100, weights=frame_phsp['weights'],\n",
    "                          density=True, histtype='step', color='red', label='fit', **kwargs);\n",
    "    plt.ylabel('normalized intensity')\n",
    "    title = replace_ids(name)\n",
    "    plt.xlabel(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_comparison('theta_2_4_vs_3')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_comparison('mSq_(3,4)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can easily create a Dalitz plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def dalitz_plot(frame, mass_x, mass_y, **kwargs):\n",
    "    \"\"\"Helper function to create a Dalitz plot with meaningful axis titles\"\"\"\n",
    "    plt.hist2d(\n",
    "        frame[mass_x],\n",
    "        frame[mass_y],\n",
    "        weights=frame['weights'],\n",
    "        **kwargs\n",
    "    );\n",
    "    plt.xlabel(replace_ids(mass_x))\n",
    "    plt.ylabel(replace_ids(mass_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "variable_names = data_set.data.keys()\n",
    "invariant_masses = [var for var in variable_names\n",
    "                    if var.startswith('mSq_')\n",
    "                    and not var.endswith('(2,3,4)')]\n",
    "for comb in combinations(invariant_masses, 2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    plt.sca(axs[0])\n",
    "    dalitz_plot(frame_data, *comb, bins=100)\n",
    "    axs[0].set_title('data')\n",
    "    plt.sca(axs[1])\n",
    "    dalitz_plot(frame_phsp, *comb, bins=100)\n",
    "    axs[1].set_title('fit')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit Fractions\n",
    "\n",
    "Fit fractions can be calculated using the ``fit_fractions_with_propagated_errors()`` function. It requires amplitude or ``Intensity`` components that can be extracted from the ``IntensityBuilderXML`` instance. A nested list of the component names has to be specified as well. These are the names specified in the component XML attributes. If the inner lists contain more than one component, these components will be added coherently. In this way you can calculate your own customized fit fractions.\n",
    "\n",
    "All registered component names can be retrieved via ``get_all_component_names()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_builder.get_all_component_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify which components you want to get from the builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = intensity_builder.create_intensity_components([\n",
    "    ['coherent_J/psi_-1_to_gamma_-1+pi0_0+pi0_0'],\n",
    "    ['J/psi_-1_to_f2(1270)_-1+gamma_-1;f2(1270)_-1_to_pi0_0+pi0_0;'],\n",
    "    ['J/psi_-1_to_f2(1270)_-2+gamma_-1;f2(1270)_-2_to_pi0_0+pi0_0;'],\n",
    "    ['J/psi_-1_to_f2(1270)_0+gamma_-1;f2(1270)_0_to_pi0_0+pi0_0;'],    \n",
    "    ['J/psi_-1_to_f2(1270)_-1+gamma_-1;f2(1270)_-1_to_pi0_0+pi0_0;',\n",
    "     'J/psi_-1_to_f2(1270)_-2+gamma_-1;f2(1270)_-2_to_pi0_0+pi0_0;',\n",
    "     'J/psi_-1_to_f2(1270)_0+gamma_-1;f2(1270)_0_to_pi0_0+pi0_0;'],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to call the actual fit fraction calculation function ``fit_fractions_with_propagated_errors()``. Here, the first required argument is a list of component pairs. Each pair resembles the nominator and denominator of a fit fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_fractions = pwa.fit_fractions_with_propagated_errors(\n",
    "    [(components[1], components[0]),\n",
    "     (components[2], components[0]),\n",
    "     (components[3], components[0]),\n",
    "     (components[4], components[0]),\n",
    "    ], phsp_set, fit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You can check some of the other examples to learn about more detailed features of ComPWA.\n",
    "\n",
    "And give us feedback or [contribute](https://compwa.github.io/contribute.html)! ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
